{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "906e07f6e562"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adapted from the Google Gemini \"cookbook\" found here: https://github.com/google-gemini/cookbook/tree/main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "IbKkL5ksQYq1"
      },
      "outputs": [],
      "source": [
        "# %pip install -U -q 'google-genai'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0H_lRdlrQYq3"
      },
      "outputs": [],
      "source": [
        "with open('../gemini.key', 'r') as file:\n",
        "    GOOGLE_API_KEY = file.read()[:-1]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "X3CAp9YrQYq4"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IO7IoqbrQYq5"
      },
      "outputs": [],
      "source": [
        "model_name = \"gemini-2.0-flash\" # @param [\"gemini-1.5-flash-latest\",\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.0-pro-exp-02-05\"] {\"allow-input\":true, isTemplate: true}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv8ULT0lvJ47"
      },
      "source": [
        "### Get sample videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fMcwUw48vL1N"
      },
      "outputs": [],
      "source": [
        "# Load sample images\n",
        "# !wget https://storage.googleapis.com/generativeai-downloads/videos/Pottery.mp4 -O Pottery.mp4 -q\n",
        "# !wget https://storage.googleapis.com/generativeai-downloads/videos/Jukin_Trailcam_Videounderstanding.mp4 -O Trailcam.mp4 -q\n",
        "# !wget https://storage.googleapis.com/generativeai-downloads/videos/post_its.mp4 -O Post_its.mp4 -q\n",
        "# !wget https://storage.googleapis.com/generativeai-downloads/videos/user_study.mp4 -O User_study.mp4 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "LUUMJ4kE0OZS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Waiting for video to be processed.\n",
            "Waiting for video to be processed.\n",
            "Video processing complete: https://generativelanguage.googleapis.com/v1beta/files/6amx0mm1k0an\n",
            "Waiting for video to be processed.\n",
            "Video processing complete: https://generativelanguage.googleapis.com/v1beta/files/jixi6940mzfs\n",
            "Waiting for video to be processed.\n",
            "Video processing complete: https://generativelanguage.googleapis.com/v1beta/files/e3zz14tvhw2d\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "def upload_video(video_file_name):\n",
        "  video_file = client.files.upload(file=video_file_name)\n",
        "\n",
        "  while video_file.state == \"PROCESSING\":\n",
        "      print('Waiting for video to be processed.')\n",
        "      time.sleep(10)\n",
        "      video_file = client.files.get(name=video_file.name)\n",
        "\n",
        "  if video_file.state == \"FAILED\":\n",
        "    raise ValueError(video_file.state)\n",
        "  print(f'Video processing complete: ' + video_file.uri)\n",
        "\n",
        "  return video_file\n",
        "\n",
        "#pottery_video = upload_video('Pottery.mp4')\n",
        "trailcam_video = upload_video('Trailcam.mp4')\n",
        "post_its_video = upload_video('Post_its.mp4')\n",
        "user_study_video = upload_video('User_study.mp4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF5tDbb-Q0oc"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "B0Z9QzC3Q2wX"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from PIL import Image\n",
        "from IPython.display import display, Markdown, HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "PZw41-lsKKMf"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "```json\n",
              "[\n",
              "  {\n",
              "    \"00:00\": \"A camera placed in the woods shows a gray fox walk toward the camera and then away from it. As it walks off, a second fox comes into view and approaches the first fox. Then one climbs on a rock.\"\n",
              "  },\n",
              "  {\n",
              "    \"00:16\": \"The video transitions to black and white and shows a mountain lion walking in the woods looking for something on the ground. At [00:00:28] it looks up and shakes its head as though it heard or sensed something.\"\n",
              "  },\n",
              "  {\n",
              "    \"00:35\": \"The video cuts to black and white and shows two foxes wandering around in the woods. One is trying to dig something out of the ground. At [00:00:49] the fox succeeds and the other fox grabs it, and the action becomes blurred because the foxes fight with each other. Eventually the action stops and you can see the two foxes on top of some rocks. One then wanders off and the other stays.\"\n",
              "  },\n",
              "  {\n",
              "    \"01:05\": \"The scene is now in black and white and shows a mountain lion walk in to the left of the camera. After it has been on the scene for a little while, it walks down to the left of the camera and another mountain lion walks into view on top of a rock. The lion on the rock walks down to the left of the camera and joins the other lion.\"\n",
              "  },\n",
              "  {\n",
              "    \"01:22\": \"The mountain lion is followed and after a few moments it comes into view and walks directly toward the camera. As it gets closer, it is difficult to see but eventually it walks past and to the left of the camera.\"\n",
              "  },\n",
              "  {\n",
              "    \"01:28\": \"A bobcat appears and walks towards the camera, stopping for a moment and sniffing the ground. The bobcat looks up, then continues to look around the woods and sniff the ground.\"\n",
              "  },\n",
              "  {\n",
              "    \"01:51\": \"The scene now features color video and shows a brown bear walk towards the camera and partially block the view of the camera. It then turns around and walks to the right of the camera. As it does that, you can see another brown bear following it.\"\n",
              "  },\n",
              "  {\n",
              "    \"01:57\": \"The scene again turns black and white and shows a mountain lion walking toward the right of the camera.\"\n",
              "  },\n",
              "  {\n",
              "    \"02:04\": \"Again the camera gets too close to the animal. The animal walks away from the camera. After a little while it comes into view again and smells around the ground.\"\n",
              "  },\n",
              "  {\n",
              "    \"02:23\": \"The camera is now set up on a hill overlooking a city. It is nighttime and you can see the city lights. A gray fox comes into view and looks around a little. It smells around a little and then sits up on its haunches and stares at the city.\"\n",
              "  },\n",
              "  {\n",
              "    \"02:34\": \"A bear walks into view and appears to attempt to sniff something on the ground. The animal leaves view. \\nThen, a mountain lion walks toward the camera, then away. \"\n",
              "  },\n",
              "  {\n",
              "    \"02:52\": \"A mountain lion wanders around and smells the ground.\"\n",
              "  },\n",
              "  {\n",
              "    \"03:05\": \"Two black bear cubs and their mother walk around and look for food. One of them stops and cleans itself.\"\n",
              "  },\n",
              "  {\n",
              "    \"04:22\": \"The camera is in the woods and it is black and white, and you can see a bobcat in front of the camera. The bobcat looks around, then jumps over the log and looks directly at the camera. The bobcat comes down from the log and looks directly at the camera. It then goes off to the right of the screen and stops and looks around again before exiting.\"\n",
              "  },\n",
              "  {\n",
              "    \"04:57\": \"A mountain lion wanders around and sniffs the ground.\"\n",
              "  }\n",
              "]\n",
              "```"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"For each scene in this video, generate captions that describe the scene along with any spoken text placed in quotation marks. Place each caption into an object with the timecode of the caption in the video.\"  # @param [\"For each scene in this video, generate captions that describe the scene along with any spoken text placed in quotation marks. Place each caption into an object with the timecode of the caption in the video.\", \"Organize all scenes from this video in a table, along with timecode, a short description, a list of objects visible in the scene (with representative emojis) and an estimation of the level of excitement on a scale of 1 to 10\"] {\"allow-input\":true}\n",
        "\n",
        "video = trailcam_video # @param [\"trailcam_video\", \"pottery_video\", \"post_its_video\", \"user_study_video\"] {\"type\":\"raw\",\"allow-input\":true}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=[\n",
        "        video,\n",
        "        prompt,\n",
        "    ]\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Video_understanding.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
